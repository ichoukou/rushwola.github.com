# hdfs 完全分布式搭建

机器规划
![ss](assets/markdown-img-paste-20181120211727563.png)

1. 时间同步,网络免密码登录(namenode到所有的datanode,此处为node1==>node1-4),修改hosts文件,防火墙关闭

```
设置主机名:
vim /etc/sysconfig/network
vim /etc/hosts

安装时间同步
yum install ntp -y
ntpdate -u cn.pool.ntp.org

防火墙关闭
/etc/init.d/iptables stop
setenforce 0

免密码登录(node01=>node01,node01=>node01-04)
在node01上执行:
ssh-keygen -t rsa
ssh-copy-id -i ~/.ssh/id_rsa.pub node01
ssh-copy-id -i ~/.ssh/id_rsa.pub node02
ssh-copy-id -i ~/.ssh/id_rsa.pub node03
ssh-copy-id -i ~/.ssh/id_rsa.pub node04
```

2. 安装jdk
3. 上传安装文件,解压
4. 修改配置文件
    hadoop-env.sh 中的JAVA_HOME:
    ```
    export JAVA_HOME=/opt/jdk1.8.0_191

    ```
    core-site.xml
    ```
    <configuration>
    	<property>
    		<name>hadoop.tmp.dir</name>
    		<value>/opt/hadoop</value>
    	</property>
    	<property>
    		<name>fs.default.name</name>
    		<value>hdfs://node01:9000</value>
    	</property>
   </configuration>

    ```
    hdfs-site.xml
    ```
    <configuration>
    	<property>
    		<name>dfs.replication</name>
    		<value>3</value>
    	</property>
      <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node02:50090</value>
      </property>
  </configuration>

    ```
    slaves 指定datanode
    ```
    node02
    node03
    node04
    ```
    手动创建masters 指家SNN
    ```
    node02
    ```
5. 同步配置文件,保证集群每台服务器配置都相同
6. 格式化namenode hdfs namenode -format
7. 启动 start-dfs.sh


错误:
```
2018-11-21 05:36:15,187 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.net.UnknownHostException: bogon: bogon: Name or service not known
	at java.net.InetAddress.getLocalHost(InetAddress.java:1506)
	at org.apache.hadoop.security.SecurityUtil.getLocalHostName(SecurityUtil.java:187)
	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:207)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2217)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2266)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2442)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2466)
Caused by: java.net.UnknownHostException: bogon: Name or service not known
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324)
	at java.net.InetAddress.getLocalHost(InetAddress.java:1501)
	... 6 more

这是由于hostname没有设置成功的原因,要重新设置hostname
```

执行命令时报错:
```
18/11/22 06:50:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

```

原因可能是hadoop的预编译包与操作系统的不一致,比如hadoop的预编译包是32bit的而linux是64位.
我可以检查一下:
```
进入hadoop的lib/native目录
ldd libhadoop.so.1.0.0

./libhadoop.so.1.0.0: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by ./libhadoop.so.1.0.0)
	linux-vdso.so.1 =>  (0x00007fff705e3000)
	libdl.so.2 => /lib64/libdl.so.2 (0x00007f41dba8c000)
	libc.so.6 => /lib64/libc.so.6 (0x00007f41db6f7000)
	/lib64/ld-linux-x86-64.so.2 (0x0000003724200000)

可见原来系统预装的glibc库是2.12版本，而hadoop期望是2.14版本，所以打印警告信息.

```

解决方法:安装glibc2.14

下载地址:http://ftp.gnu.org/gnu/glibc/
具体操作可看:https://www.cnblogs.com/erygreat/p/7223829.html;


# ha namenode

机器规划

![](assets/markdown-img-paste-20181123224556234.png)

1. 时间同步,jdk,修改hosts文件,防火墙关闭

2. 网络免密码登录

node01到 node01-04
node02 到 node01-04
两台NN 之间也要做免密钥登录

3. 修改配置文件
 1.x当中创建的masters文件一定要保证每台服务器都删除.

 
